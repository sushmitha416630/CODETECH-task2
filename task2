Linear Regression on Housing Prices:

Linear regression for predicting house prices is a machine learning approach that finds the relationship between input features (like square footage, number of rooms) and the target
variable (price). 
The model tries to fit a straight line through the data points, which represents the equation \( y = b_0 + b_1x_1 + b_2x_2 + ... + b_nx_n \), where \( b_0 \) is the intercept 
and \( b_1, b_2, ... \) are the coefficients. These coefficients indicate how each feature impacts the price. Once trained, the model can predict house prices based on new feature inputs.
The model’s accuracy is typically evaluated using metrics like Mean Squared Error (MSE), where lower values indicate better predictions.

from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import SimpleRNN, Dense, Dropout
import matplotlib.pyplot as plt
# Load the dataset
data = pd.read_csv("/content/drive/MyDrive/housepriceprediction.csv")
# Display the first few rows of the data
print(data.head())
# Check the shape of the dataset
print(data.shape)
# Convert 'Date' column to datetime objects
data['Date'] = pd.to_datetime(data['Date'])
# Extract features from datetime
data['year'] = data['Date'].dt.year
data['month'] = data['Date'].dt.month
data['day'] = data['Date'].dt.day
# Define features and target
features = ['year', 'month', 'day']
X = data[features]
y = data[['Open', 'High']]
# Scale the data
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
y_scaled = scaler.fit_transform(y)
# Create sequences for RNN
timesteps = 50
X_sequences = []
y_sequences = []
for i in range(timesteps, len(X_scaled)):
    X_sequences.append(X_scaled[i-timesteps:i])
    y_sequences.append(y_scaled[i])
X_sequences, y_sequences = np.array(X_sequences), np.array(y_sequences)
# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=0)
# Build the RNN model
model = Sequential()
model.add(SimpleRNN(50, activation="tanh", input_shape=(timesteps, X_sequences.shape[2]), return_sequences=True))
model.add(Dropout(0.2))
model.add(SimpleRNN(50, activation="tanh", return_sequences=True))
model.add(Dropout(0.2))
model.add(SimpleRNN(50, activation="tanh", return_sequences=True))
model.add(Dropout(0.2))
model.add(SimpleRNN(50))
model.add(Dropout(0.2))
model.add(Dense(2, activation='linear'))
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])
# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=1)
# Test the model
y_pred_scaled = model.predict(X_test)
y_pred = scaler.inverse_transform(y_pred_scaled)  # Inverse scale the predicted values
y_test_true = scaler.inverse_transform(y_test)  # Inverse scale the true test values
import matplotlib.pyplot as plt

# Plot predictions
plt.figure(figsize=(10, 5))

# Subplot for true open prices
plt.subplot(2, 2, 1)
plt.plot(y_test_true[:, 0], label='True Open Price', color='magenta')
plt.title('True Open Prices')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()

# Subplot for true high prices
plt.subplot(2, 2, 2)
plt.plot(y_test_true[:, 1], label='True High Price', color='blue')
plt.title('True High Prices')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()

# Subplot for predicted open prices
plt.subplot(2, 2, 3)
plt.plot(y_pred[:, 0], label='Predicted Open Price', color='orange')
plt.title('Predicted Open Prices')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()

# Subplot for predicted high prices
plt.subplot(2, 2, 4)
plt.plot(y_pred[:, 1], label='Predicted High Price', color='green')
plt.title('Predicted High Prices')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()

# Adjust layout to avoid overlap
plt.tight_layout()
plt.show()

